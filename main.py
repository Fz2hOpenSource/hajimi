import cv2
import numpy as np
import multiprocessing as mp
import sys
import os
import time
import json
from PIL import Image, ImageDraw, ImageFont
from ultralytics import YOLO

# ================= é…ç½®åŒºåŸŸ =================
VOSK_MODEL_PATH = "vosk-model-small-cn-0.22"
YOLO_MODEL_NAME = "D:\Fun\hajimi\yolo11s.pt"
EMBEDDING_MODEL_NAME = "paraphrase-multilingual-MiniLM-L12-v2"
# ä¸­æ–‡å­—ä½“è·¯å¾„ (å°è¯•ç³»ç»Ÿè‡ªå¸¦çš„å¾®è½¯é›…é»‘)
FONT_PATH = "C:/Windows/Fonts/msyh.ttc"

# è‹±æ–‡ -> ä¸­æ–‡ ç¼“å­˜å­—å…¸
EN_ZH_CACHE = {
    "person": "äºº", "bicycle": "è‡ªè¡Œè½¦", "car": "æ±½è½¦", "motorcycle": "æ‘©æ‰˜è½¦", "airplane": "é£æœº",
    "bus": "å…¬äº¤è½¦", "train": "ç«è½¦", "truck": "å¡è½¦", "boat": "èˆ¹", "traffic light": "çº¢ç»¿ç¯",
    "fire hydrant": "æ¶ˆé˜²æ “", "stop sign": "åœè½¦æ ‡å¿—", "parking meter": "åœè½¦è®¡æ—¶å™¨", "bench": "é•¿æ¤…",
    "bird": "é¸Ÿ", "cat": "çŒ«", "dog": "ç‹—", "horse": "é©¬", "sheep": "ç¾Š", "cow": "ç‰›",
    "elephant": "å¤§è±¡", "bear": "ç†Š", "zebra": "æ–‘é©¬", "giraffe": "é•¿é¢ˆé¹¿", "backpack": "èƒŒåŒ…",
    "umbrella": "é›¨ä¼", "handbag": "æ‰‹æåŒ…", "tie": "é¢†å¸¦", "suitcase": "æ‰‹æç®±", "frisbee": "é£ç›˜",
    "skis": "æ»‘é›ªæ¿", "snowboard": "å•æ¿æ»‘é›ª", "sports ball": "çƒ", "kite": "é£ç­",
    "baseball bat": "æ£’çƒæ£’", "baseball glove": "æ£’çƒæ‰‹å¥—", "skateboard": "æ»‘æ¿",
    "surfboard": "å†²æµªæ¿", "tennis racket": "ç½‘çƒæ‹", "bottle": "ç“¶å­", "wine glass": "é…’æ¯",
    "cup": "æ¯å­", "fork": "å‰å­", "knife": "åˆ€", "spoon": "å‹ºå­", "bowl": "ç¢—", "banana": "é¦™è•‰",
    "apple": "è‹¹æœ", "sandwich": "ä¸‰æ˜æ²»", "orange": "æ©˜å­", "broccoli": "è¥¿å…°èŠ±", "carrot": "èƒ¡èåœ",
    "hot dog": "çƒ­ç‹—", "pizza": "æŠ«è¨", "donut": "ç”œç”œåœˆ", "cake": "è›‹ç³•", "chair": "æ¤…å­",
    "couch": "æ²™å‘", "potted plant": "ç›†æ ½", "bed": "åºŠ", "dining table": "é¤æ¡Œ", "toilet": "é©¬æ¡¶",
    "tv": "ç”µè§†", "laptop": "ç¬”è®°æœ¬ç”µè„‘", "mouse": "é¼ æ ‡", "remote": "é¥æ§å™¨", "keyboard": "é”®ç›˜",
    "cell phone": "æ‰‹æœº", "microwave": "å¾®æ³¢ç‚‰", "oven": "çƒ¤ç®±", "toaster": "çƒ¤é¢åŒ…æœº", "sink": "æ°´æ§½",
    "refrigerator": "é›ªæŸœ", "book": "ä¹¦", "clock": "æ—¶é’Ÿ", "vase": "èŠ±ç“¶", "scissors": "å‰ªåˆ€",
    "teddy bear": "æ³°è¿ªç†Š", "hair drier": "å¹é£æœº", "toothbrush": "ç‰™åˆ·"
}

# ================= å­è¿›ç¨‹ï¼šè¯­éŸ³ä¸è¯­ä¹‰å¤„ç† =================
class QueueLogger:
    """é‡å®šå‘ stdout/stderr åˆ°ä¸»è¿›ç¨‹çš„é˜Ÿåˆ—ï¼Œé˜²æ­¢ Windows å¥æŸ„æ— æ•ˆé”™è¯¯"""
    def __init__(self, queue, prefix="[Child]"):
        self.queue = queue
        self.prefix = prefix
    
    def write(self, message):
        if message.strip():
            self.queue.put(("log", f"{self.prefix} {message.strip()}"))
            
    def flush(self):
        pass

def voice_process_run(msg_queue, cache_items, vosk_path, embed_model_name):
    """
    è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼š
    1. åŠ è½½ Vosk å’Œ SentenceTransformer
    2. è®¡ç®—ç¼“å­˜å­—å…¸çš„å‘é‡å¹¶å‘é€ç»™ä¸»è¿›ç¨‹
    3. ç›‘å¬éº¦å…‹é£ -> è½¬æ–‡å­— -> è½¬å‘é‡ -> å‘é€ç»™ä¸»è¿›ç¨‹
    """
    # é‡å®šå‘æ ‡å‡†è¾“å‡ºï¼Œé˜²æ­¢ [WinError 6] å¥æŸ„æ— æ•ˆ
    sys.stdout = QueueLogger(msg_queue, "[Child]")
    sys.stderr = QueueLogger(msg_queue, "[Child Error]")
    
    print("æ­£åœ¨åˆå§‹åŒ–è¯­éŸ³ä¸è¯­ä¹‰å¼•æ“...")
    
    try:
        from sentence_transformers import SentenceTransformer
        import sounddevice as sd
        import vosk
        
        # é™éŸ³ Vosk åº•å±‚æ—¥å¿—
        vosk.SetLogLevel(-1)
    except ImportError as e:
        msg_queue.put(("error", f"ç¼ºå°‘ä¾èµ–: {e}"))
        return

    # 1. åŠ è½½æ¨¡å‹
    try:
        # åŠ è½½å‘é‡æ¨¡å‹
        embedder = SentenceTransformer(embed_model_name)
        print("å‘é‡æ¨¡å‹åŠ è½½å®Œæˆ")

        # åŠ è½½è¯­éŸ³æ¨¡å‹
        final_path = vosk_path
        # è‡ªåŠ¨æ£€æµ‹åµŒå¥—ç›®å½• (ä¾‹å¦‚è§£å‹æ—¶å¤šäº†ä¸€å±‚ vosk-model-small-cn-0.22)
        if os.path.exists(os.path.join(vosk_path, vosk_path)):
             final_path = os.path.join(vosk_path, vosk_path)
        
        if not os.path.exists(final_path) or not os.path.exists(os.path.join(final_path, "conf")):
            msg_queue.put(("error", f"æ— æ•ˆçš„ Vosk æ¨¡å‹è·¯å¾„: {final_path} (è¯·æ£€æŸ¥ conf æ–‡ä»¶å¤¹)"))
            return
            
        vosk_model = vosk.Model(final_path)
        print(f"Vosk è¯­éŸ³æ¨¡å‹åŠ è½½å®Œæˆ (è·¯å¾„: {final_path})", flush=True)

    except Exception as e:
        msg_queue.put(("error", f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}"))
        return

    # 2. é¢„è®¡ç®—æ‰€æœ‰ç±»åˆ«çš„ä¸­æ–‡å‘é‡
    # æå–æ‰€æœ‰å”¯ä¸€çš„ä¸­æ–‡æ ‡ç­¾
    unique_labels = list(set(cache_items.values()))
    print(f"æ­£åœ¨é¢„è®¡ç®— {len(unique_labels)} ä¸ªç±»åˆ«çš„å‘é‡...")
    
    label_vectors = {}
    for label in unique_labels:
        vec = embedder.encode(label, normalize_embeddings=True)
        label_vectors[label] = vec
    
    # å‘é€åˆå§‹åŒ–æ•°æ®å›ä¸»è¿›ç¨‹
    msg_queue.put(("init_vectors", label_vectors))
    print("åˆå§‹åŒ–å‘é‡å·²å‘é€")

    # 3. å¼€å¯éŸ³é¢‘ç›‘å¬å¾ªç¯
    q_audio = mp.Queue()

    def audio_callback(indata, frames, time, status):
        if status:
            # è¿™é‡Œçš„ print ä¹Ÿä¼šè¢«é‡å®šå‘
            print(f"Audio Error: {status}")
        q_audio.put(bytes(indata))

    try:
        samplerate = 16000
        rec = vosk.KaldiRecognizer(vosk_model, samplerate)
        
        print("ğŸ¤ éº¦å…‹é£ç›‘å¬ä¸­...")
        
        # ä½¿ç”¨ sounddevice å¼€å¯æµ
        with sd.RawInputStream(samplerate=samplerate, blocksize=8000, device=None,
                               dtype='int16', channels=1, callback=audio_callback):
            while True:
                data = q_audio.get()
                if rec.AcceptWaveform(data):
                    res = json.loads(rec.Result())
                    text = res.get("text", "").strip()
                    if text:
                        text = text.replace(" ", "")
                        print(f"è¯†åˆ«åˆ°è¯­éŸ³: {text}")
                        # è®¡ç®—è¯­éŸ³å‘é‡
                        voice_vec = embedder.encode(text, normalize_embeddings=True)
                        # å‘é€ç»™ä¸»è¿›ç¨‹
                        msg_queue.put(("voice", (text, voice_vec)))
    except Exception as e:
        msg_queue.put(("error", f"éŸ³é¢‘å¾ªç¯å‡ºé”™: {e}"))

# ================= ä¸»è¿›ç¨‹ï¼šUI ä¸ è§†è§‰ =================

def ensure_cat_image():
    if not os.path.exists("hajimi.png"):
        img = np.zeros((100, 100, 4), dtype=np.uint8)
        cv2.circle(img, (50, 50), 40, (0, 255, 255, 255), -1)
        cv2.circle(img, (35, 40), 5, (0, 0, 0, 255), -1)
        cv2.circle(img, (65, 40), 5, (0, 0, 0, 255), -1)
        cv2.ellipse(img, (50, 60), (10, 5), 0, 0, 180, (0, 0, 0, 255), 2)
        cv2.imwrite("hajimi.png", img)

def overlay_img(background, overlay, x, y):
    h, w = overlay.shape[:2]
    if x < 0 or y < 0 or x + w > background.shape[1] or y + h > background.shape[0]:
        return
    alpha = overlay[:, :, 3] / 255.0
    for c in range(0, 3):
        background[y:y+h, x:x+w, c] = (alpha * overlay[:, :, c] + 
                                      (1 - alpha) * background[y:y+h, x:x+w, c])

def draw_text_chinese(img, text, position, textColor=(0, 255, 0), textSize=20):
    if (isinstance(img, np.ndarray)):  # åˆ¤æ–­æ˜¯å¦OpenCVå›¾ç‰‡ç±»å‹
        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    
    draw = ImageDraw.Draw(img)
    # æ£€æŸ¥å­—ä½“æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤
    try:
        font = ImageFont.truetype(FONT_PATH, textSize, encoding="utf-8")
    except:
        font = ImageFont.load_default()
        print(f"è­¦å‘Šï¼šæ— æ³•åŠ è½½å­—ä½“ {FONT_PATH}ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
        
    draw.text(position, text, textColor, font=font)
    
    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)

def draw_cat_pointing(frame, target_box, cat_img):
    if cat_img is None: return
    h, w, _ = frame.shape
    cat_h, cat_w = cat_img.shape[:2]
    pos_x, pos_y = 20, h - cat_h - 20
    overlay_img(frame, cat_img, pos_x, pos_y)
    
    x1, y1, x2, y2 = target_box
    cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
    start_pt = (pos_x + cat_w // 2, pos_y + cat_h // 2)
    cv2.arrowedLine(frame, start_pt, (cx, cy), (0, 255, 0), 3, tipLength=0.1)
    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)

def main():
    # å¿…é¡»è°ƒç”¨ï¼Œé˜²æ­¢ Windows ä¸‹å¤šè¿›ç¨‹å‡ºé”™
    mp.freeze_support()

    ensure_cat_image()
    cat_img = cv2.imread("hajimi.png", cv2.IMREAD_UNCHANGED)

    # 1. å¯åŠ¨å­è¿›ç¨‹
    msg_queue = mp.Queue()
    process = mp.Process(target=voice_process_run, 
                         args=(msg_queue, EN_ZH_CACHE, VOSK_MODEL_PATH, EMBEDDING_MODEL_NAME))
    process.start()

    print("[Main] ç­‰å¾…å­è¿›ç¨‹åˆå§‹åŒ–...")
    
    # 2. ç­‰å¾…åˆå§‹åŒ–å‘é‡
    known_vectors = {}
    
    # ç®€å•çš„éé˜»å¡ç­‰å¾…åŠ è½½ UI ä¹‹å‰
    while True:
        try:
            msg = msg_queue.get(timeout=0.1)
            if msg[0] == "init_vectors":
                known_vectors = msg[1]
                print(f"[Main] å·²æ¥æ”¶ {len(known_vectors)} ä¸ªç±»åˆ«çš„å‘é‡æ•°æ®")
                break
            elif msg[0] == "error":
                print(f"[Error from Child] {msg[1]}")
                process.terminate()
                return
        except:
            pass
        # å¯ä»¥åœ¨è¿™é‡Œæ‰“å°åŠ è½½åŠ¨ç”»ï¼Œæš‚æ—¶ç•¥è¿‡

    # 3. åŠ è½½ YOLO (ä¸»è¿›ç¨‹)
    print("[Main] æ­£åœ¨åŠ è½½ YOLO...")
    try:
        yolo_model = YOLO(YOLO_MODEL_NAME)
    except Exception as e:
        print(f"YOLO åŠ è½½å¤±è´¥: {e}")
        process.terminate()
        return

    # 4. ä¸»å¾ªç¯
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        process.terminate()
        return

    print("[Main] ç³»ç»Ÿå¯åŠ¨å®Œæˆï¼")
    
    last_voice_vector = None
    last_voice_text = ""

    while True:
        ret, frame = cap.read()
        if not ret: break
        frame = cv2.flip(frame, 1)

        # æ£€æŸ¥æ¶ˆæ¯é˜Ÿåˆ— (éé˜»å¡)
        while not msg_queue.empty():
            try:
                msg_type, data = msg_queue.get_nowait()
                if msg_type == "voice":
                    text, vec = data
                    print(f"[Main] æ›´æ–°æŒ‡ä»¤: {text}")
                    last_voice_text = text
                    last_voice_vector = vec
                elif msg_type == "error":
                    print(f"[Error] {data}")
                elif msg_type == "log":
                    print(data)
            except:
                break

        # YOLO æ£€æµ‹
        results = yolo_model(frame, verbose=False)[0]
        scene_objects = []

        for box in results.boxes:
            cls_id = int(box.cls[0])
            en_name = yolo_model.names[cls_id]
            zh_name = EN_ZH_CACHE.get(en_name, en_name)
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            scene_objects.append({"zh": zh_name, "box": (x1, y1, x2, y2)})

        # åŒ¹é…é€»è¾‘
        best_idx = -1
        best_score = 0.3 # é˜ˆå€¼
        
        if last_voice_vector is not None:
            for i, obj in enumerate(scene_objects):
                # ä»é¢„è®¡ç®—çš„å­—å…¸é‡Œå–å‘é‡
                if obj["zh"] in known_vectors:
                    obj_vec = known_vectors[obj["zh"]]
                    score = np.dot(obj_vec, last_voice_vector)
                    if score > best_score:
                        best_score = score
                        best_idx = i

        # ç»˜åˆ¶
        for i, obj in enumerate(scene_objects):
            x1, y1, x2, y2 = obj["box"]
            color = (200, 200, 200)
            if i == best_idx: color = (0, 255, 0)
            
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            # ä½¿ç”¨ PIL ç»˜åˆ¶ä¸­æ–‡
            frame = draw_text_chinese(frame, obj["zh"], (x1, y1 - 30), color, 20)

        if best_idx != -1:
            draw_cat_pointing(frame, scene_objects[best_idx]["box"], cat_img)

        # æ˜¾ç¤ºå½“å‰æŒ‡ä»¤
        if last_voice_text:
             frame = draw_text_chinese(frame, f"æŒ‡ä»¤: {last_voice_text}", (10, 30), (255, 255, 0), 25)

        cv2.imshow("Hajimi AI (Multi-Process)", frame)
        if cv2.waitKey(1) & 0xFF == 27:
            break

    cap.release()
    cv2.destroyAllWindows()
    process.terminate()

if __name__ == "__main__":
    main()
