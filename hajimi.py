import cv2
import numpy as np
import multiprocessing as mp
import sys
import os
import time
import json
import platform
import webbrowser
import customtkinter as ctk
from PIL import Image, ImageDraw, ImageFont, ImageTk
from ultralytics import YOLO

# ================= é…ç½®åŒºåŸŸ =================
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

VOSK_MODEL_PATH = os.path.join(BASE_DIR, "vosk-model-small-cn-0.22")
# å°è¯•æŸ¥æ‰¾å½“å‰ç›®å½•ä¸‹çš„ yolo11*.pt æ–‡ä»¶ï¼Œé»˜è®¤ä½¿ç”¨ s ç‰ˆæœ¬
YOLO_MODEL_NAME = os.path.join(BASE_DIR, "yolo11n.pt")
EMBEDDING_MODEL_NAME = "paraphrase-multilingual-MiniLM-L12-v2"

# ä¸ªäººä¸»é¡µé“¾æ¥
USER_HOMEPAGE = "https://github.com/your-username" 

def get_font_path():
    """æ ¹æ®æ“ä½œç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©ä¸­æ–‡å­—ä½“è·¯å¾„"""
    system = platform.system()
    if system == "Windows":
        return "C:/Windows/Fonts/msyh.ttc" # å¾®è½¯é›…é»‘
    elif system == "Darwin": # macOS
        return "/System/Library/Fonts/PingFang.ttc" # è‹¹æ–¹
    elif system == "Linux":
        # å°è¯•ä¸€äº›å¸¸è§çš„ Linux ä¸­æ–‡å­—ä½“è·¯å¾„
        paths = [
            "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",
            "/usr/share/fonts/wqy-microhei/wqy-microhei.ttc",
            "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf"
        ]
        for p in paths:
            if os.path.exists(p):
                return p
    return None # æ­¤æ—¶å°†ä½¿ç”¨ PIL é»˜è®¤å­—ä½“

FONT_PATH = get_font_path()

def check_models():
    """æ£€æŸ¥å¿…è¦çš„æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™æ‰“å°ä¸‹è½½é“¾æ¥"""
    missing = []
    global YOLO_MODEL_NAME
    # 1. æ£€æŸ¥ YOLO æ¨¡å‹
    # å¦‚æœæŒ‡å®šè·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•æœå¯»åŒç›®å½•ä¸‹çš„å…¶ä»– pt æ–‡ä»¶
    if not os.path.exists(YOLO_MODEL_NAME):
        found = False
        for f in os.listdir(BASE_DIR):
            if f.endswith(".pt") and "yolo" in f.lower():

                YOLO_MODEL_NAME = os.path.join(BASE_DIR, f)
                found = True
                print(f"[Info] æœªæ‰¾åˆ° yolo11s.ptï¼Œè‡ªåŠ¨ä½¿ç”¨: {f}")
                break
        if not found:
            missing.append({
                "name": "YOLOv11 æ¨¡å‹ (yolo11s.pt)",
                "url": "https://github.com/ultralytics/ultralytics",
                "path": "é¡¹ç›®æ ¹ç›®å½•"
            })

    # 2. æ£€æŸ¥ Vosk æ¨¡å‹
    # æ£€æŸ¥ VOSK_MODEL_PATH æ˜¯å¦å­˜åœ¨ï¼Œä¸”é‡Œé¢æœ‰ conf æ–‡ä»¶å¤¹
    # ä¹Ÿè¦å…¼å®¹è§£å‹åå¤šå¥—ä¸€å±‚çš„æƒ…å†µ
    global VOSK_MODEL_PATH
    valid_vosk = False
    if os.path.exists(VOSK_MODEL_PATH):
        if os.path.exists(os.path.join(VOSK_MODEL_PATH, "conf")):
            valid_vosk = True
        elif os.path.exists(os.path.join(VOSK_MODEL_PATH, os.path.basename(VOSK_MODEL_PATH), "conf")):
            # ä¿®æ­£è·¯å¾„
            VOSK_MODEL_PATH = os.path.join(VOSK_MODEL_PATH, os.path.basename(VOSK_MODEL_PATH))
            valid_vosk = True
            
    if not valid_vosk:
         missing.append({
                "name": "Vosk ä¸­æ–‡è¯­éŸ³æ¨¡å‹ (vosk-model-small-cn-0.22)",
                "url": "https://alphacephei.com/vosk/models",
                "path": "é¡¹ç›®æ ¹ç›®å½• (è§£å‹å)"
            })
            
    if missing:
        print("\n" + "="*50)
        print("âŒ é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„æ¨¡å‹æ–‡ä»¶ï¼Œç¨‹åºæ— æ³•å¯åŠ¨ã€‚")
        print("è¯·ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶å¹¶æ”¾ç½®åœ¨æ­£ç¡®ä½ç½®ï¼š")
        print("="*50)
        for item in missing:
            print(f"\nğŸ“¦ {item['name']}")
            print(f"   ğŸ”— ä¸‹è½½åœ°å€: {item['url']}")
            print(f"   ğŸ“‚ æ”¾ç½®ä½ç½®: {item['path']}")
        print("\n" + "="*50)
        print(f"ğŸ’¡ æ›´å¤šä¿¡æ¯è¯·è®¿é—®ä½œè€…ä¸»é¡µ: {USER_HOMEPAGE}")
        input("\næŒ‰å›è½¦é”®é€€å‡º...")
        sys.exit(1)

# åœ¨å¯¼å…¥æ¨¡å—åç«‹å³æ£€æŸ¥
check_models()

# è‹±æ–‡ -> ä¸­æ–‡ ç¼“å­˜å­—å…¸
EN_ZH_CACHE = {
    "person": "äºº", "bicycle": "è‡ªè¡Œè½¦", "car": "æ±½è½¦", "motorcycle": "æ‘©æ‰˜è½¦", "airplane": "é£æœº",
    "bus": "å…¬äº¤è½¦", "train": "ç«è½¦", "truck": "å¡è½¦", "boat": "èˆ¹", "traffic light": "çº¢ç»¿ç¯",
    "fire hydrant": "æ¶ˆé˜²æ “", "stop sign": "åœè½¦æ ‡å¿—", "parking meter": "åœè½¦è®¡æ—¶å™¨", "bench": "é•¿æ¤…",
    "bird": "é¸Ÿ", "cat": "çŒ«", "dog": "ç‹—", "horse": "é©¬", "sheep": "ç¾Š", "cow": "ç‰›",
    "elephant": "å¤§è±¡", "bear": "ç†Š", "zebra": "æ–‘é©¬", "giraffe": "é•¿é¢ˆé¹¿", "backpack": "èƒŒåŒ…",
    "umbrella": "é›¨ä¼", "handbag": "æ‰‹æåŒ…", "tie": "é¢†å¸¦", "suitcase": "æ‰‹æç®±", "frisbee": "é£ç›˜",
    "skis": "æ»‘é›ªæ¿", "snowboard": "å•æ¿æ»‘é›ª", "sports ball": "çƒ", "kite": "é£ç­",
    "baseball bat": "æ£’çƒæ£’", "baseball glove": "æ£’çƒæ‰‹å¥—", "skateboard": "æ»‘æ¿",
    "surfboard": "å†²æµªæ¿", "tennis racket": "ç½‘çƒæ‹", "bottle": "ç“¶å­", "wine glass": "é…’æ¯",
    "cup": "æ¯å­", "fork": "å‰å­", "knife": "åˆ€", "spoon": "å‹ºå­", "bowl": "ç¢—", "banana": "é¦™è•‰",
    "apple": "è‹¹æœ", "sandwich": "ä¸‰æ˜æ²»", "orange": "æ©˜å­", "broccoli": "è¥¿å…°èŠ±", "carrot": "èƒ¡èåœ",
    "hot dog": "çƒ­ç‹—", "pizza": "æŠ«è¨", "donut": "ç”œç”œåœˆ", "cake": "è›‹ç³•", "chair": "æ¤…å­",
    "couch": "æ²™å‘", "potted plant": "ç›†æ ½", "bed": "åºŠ", "dining table": "é¤æ¡Œ", "toilet": "é©¬æ¡¶",
    "tv": "ç”µè§†", "laptop": "ç¬”è®°æœ¬ç”µè„‘", "mouse": "é¼ æ ‡", "remote": "é¥æ§å™¨", "keyboard": "é”®ç›˜",
    "cell phone": "æ‰‹æœº", "microwave": "å¾®æ³¢ç‚‰", "oven": "çƒ¤ç®±", "toaster": "çƒ¤é¢åŒ…æœº", "sink": "æ°´æ§½",
    "refrigerator": "é›ªæŸœ", "book": "ä¹¦", "clock": "æ—¶é’Ÿ", "vase": "èŠ±ç“¶", "scissors": "å‰ªåˆ€",
    "teddy bear": "æ³°è¿ªç†Š", "hair drier": "å¹é£æœº", "toothbrush": "ç‰™åˆ·"
}

# ================= å­è¿›ç¨‹ï¼šè¯­éŸ³ä¸è¯­ä¹‰å¤„ç† =================
class QueueLogger:
    """é‡å®šå‘ stdout/stderr åˆ°ä¸»è¿›ç¨‹çš„é˜Ÿåˆ—ï¼Œé˜²æ­¢ Windows å¥æŸ„æ— æ•ˆé”™è¯¯"""
    def __init__(self, queue, prefix="[Child]"):
        self.queue = queue
        self.prefix = prefix
    
    def write(self, message):
        if message.strip():
            self.queue.put(("log", f"{self.prefix} {message.strip()}"))
            
    def flush(self):
        pass

def voice_process_run(msg_queue, cache_items, vosk_path, embed_model_name):
    """
    è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼š
    1. åŠ è½½ Vosk å’Œ SentenceTransformer
    2. è®¡ç®—ç¼“å­˜å­—å…¸çš„å‘é‡å¹¶å‘é€ç»™ä¸»è¿›ç¨‹
    3. ç›‘å¬éº¦å…‹é£ -> è½¬æ–‡å­— -> è½¬å‘é‡ -> å‘é€ç»™ä¸»è¿›ç¨‹
    """
    # é‡å®šå‘æ ‡å‡†è¾“å‡ºï¼Œé˜²æ­¢ [WinError 6] å¥æŸ„æ— æ•ˆ
    sys.stdout = QueueLogger(msg_queue, "[Child]")
    sys.stderr = QueueLogger(msg_queue, "[Child Error]")
    
    print("æ­£åœ¨åˆå§‹åŒ–è¯­éŸ³ä¸è¯­ä¹‰å¼•æ“...")
    
    try:
        from sentence_transformers import SentenceTransformer
        import sounddevice as sd
        import vosk
        
        # é™éŸ³ Vosk åº•å±‚æ—¥å¿—
        vosk.SetLogLevel(-1)
    except ImportError as e:
        msg_queue.put(("error", f"ç¼ºå°‘ä¾èµ–: {e}"))
        return

    # 1. åŠ è½½æ¨¡å‹
    try:
        # åŠ è½½å‘é‡æ¨¡å‹
        embedder = SentenceTransformer(embed_model_name)
        print("å‘é‡æ¨¡å‹åŠ è½½å®Œæˆ")

        # åŠ è½½è¯­éŸ³æ¨¡å‹
        final_path = vosk_path
        # è‡ªåŠ¨æ£€æµ‹åµŒå¥—ç›®å½• (ä¾‹å¦‚è§£å‹æ—¶å¤šäº†ä¸€å±‚ vosk-model-small-cn-0.22)
        if os.path.exists(os.path.join(vosk_path, vosk_path)):
             final_path = os.path.join(vosk_path, vosk_path)
        
        if not os.path.exists(final_path) or not os.path.exists(os.path.join(final_path, "conf")):
            msg_queue.put(("error", f"æ— æ•ˆçš„ Vosk æ¨¡å‹è·¯å¾„: {final_path} (è¯·æ£€æŸ¥ conf æ–‡ä»¶å¤¹)"))
            return
            
        vosk_model = vosk.Model(final_path)
        print(f"Vosk è¯­éŸ³æ¨¡å‹åŠ è½½å®Œæˆ (è·¯å¾„: {final_path})", flush=True)

    except Exception as e:
        msg_queue.put(("error", f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}"))
        return

    # 2. é¢„è®¡ç®—æ‰€æœ‰ç±»åˆ«çš„ä¸­æ–‡å‘é‡
    # æå–æ‰€æœ‰å”¯ä¸€çš„ä¸­æ–‡æ ‡ç­¾
    unique_labels = list(set(cache_items.values()))
    print(f"æ­£åœ¨é¢„è®¡ç®— {len(unique_labels)} ä¸ªç±»åˆ«çš„å‘é‡...")
    
    label_vectors = {}
    for label in unique_labels:
        vec = embedder.encode(label, normalize_embeddings=True)
        label_vectors[label] = vec
    
    # å‘é€åˆå§‹åŒ–æ•°æ®å›ä¸»è¿›ç¨‹
    msg_queue.put(("init_vectors", label_vectors))
    print("åˆå§‹åŒ–å‘é‡å·²å‘é€")

    # 3. å¼€å¯éŸ³é¢‘ç›‘å¬å¾ªç¯
    q_audio = mp.Queue()

    def audio_callback(indata, frames, time, status):
        if status:
            # è¿™é‡Œçš„ print ä¹Ÿä¼šè¢«é‡å®šå‘
            print(f"Audio Error: {status}")
        q_audio.put(bytes(indata))

    try:
        samplerate = 16000
        rec = vosk.KaldiRecognizer(vosk_model, samplerate)
        
        print("ğŸ¤ éº¦å…‹é£ç›‘å¬ä¸­...")
        devices = sd.query_devices()
        print(devices)  
        # ä½¿ç”¨ sounddevice å¼€å¯æµ
        with sd.RawInputStream(samplerate=samplerate, blocksize=8000, device=2,
                               dtype='int16', channels=1, callback=audio_callback):
            while True:
                data = q_audio.get()
                if rec.AcceptWaveform(data):
                    res = json.loads(rec.Result())
                    text = res.get("text", "").strip()
                    if text:
                        text = text.replace(" ", "")
                        print(f"è¯†åˆ«åˆ°è¯­éŸ³: {text}")
                        # è®¡ç®—è¯­éŸ³å‘é‡
                        voice_vec = embedder.encode(text, normalize_embeddings=True)
                        # å‘é€ç»™ä¸»è¿›ç¨‹
                        msg_queue.put(("voice", (text, voice_vec)))
    except Exception as e:
        msg_queue.put(("error", f"éŸ³é¢‘å¾ªç¯å‡ºé”™: {e}"))

# ================= è¾…åŠ©ç»˜å›¾å‡½æ•° =================

def ensure_cat_image():
    if not os.path.exists("hajimi1.png"):
        img = np.zeros((100, 100, 4), dtype=np.uint8)
        cv2.circle(img, (50, 50), 40, (0, 255, 255, 255), -1)
        cv2.circle(img, (35, 40), 5, (0, 0, 0, 255), -1)
        cv2.circle(img, (65, 40), 5, (0, 0, 0, 255), -1)
        cv2.ellipse(img, (50, 60), (10, 5), 0, 0, 180, (0, 0, 0, 255), 2)
        cv2.imwrite("hajimi1.png", img)

def overlay_img(background, overlay, x, y):
    h, w = overlay.shape[:2]
    if x < 0 or y < 0 or x + w > background.shape[1] or y + h > background.shape[0]:
        return

    # å¦‚æœæ²¡æœ‰ alpha é€šé“ï¼Œç›´æ¥è¦†ç›–
    if overlay.shape[2] == 3:
        background[y:y+h, x:x+w] = overlay
        return

    # æœ‰ alpha é€šé“ï¼ˆBGRAï¼‰
    alpha = overlay[:, :, 3] / 255.0
    for c in range(3):
        background[y:y+h, x:x+w, c] = (
            alpha * overlay[:, :, c] +
            (1 - alpha) * background[y:y+h, x:x+w, c]
        )

def draw_text_chinese(img, text, position, textColor=(0, 255, 0), textSize=20):
    if (isinstance(img, np.ndarray)):  # åˆ¤æ–­æ˜¯å¦OpenCVå›¾ç‰‡ç±»å‹
        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    
    draw = ImageDraw.Draw(img)
    # æ£€æŸ¥å­—ä½“æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤
    try:
        font = ImageFont.truetype(FONT_PATH, textSize, encoding="utf-8")
    except:
        font = ImageFont.load_default()
        print(f"è­¦å‘Šï¼šæ— æ³•åŠ è½½å­—ä½“ {FONT_PATH}ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
        
    draw.text(position, text, textColor, font=font)
    
    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)

def draw_cat(frame, cat_img, target_box=None):
    """
    ç»˜åˆ¶å“ˆåŸºç±³ã€‚
    å¦‚æœ target_box ä¸ä¸º Noneï¼Œåˆ™ç”»ç®­å¤´æŒ‡å‘ç›®æ ‡ã€‚
    å¦åˆ™ä»…åœ¨ç”»é¢ä¸­é—´æ˜¾ç¤ºå“ˆåŸºç±³ã€‚
    """
    if cat_img is None: return
    
    # æ”¾å¤§å“ˆåŸºç±³ (3å€å¤§å°)
    scale = 1
    new_w = int(cat_img.shape[1] * scale)
    new_h = int(cat_img.shape[0] * scale)
    cat_resized = cv2.resize(cat_img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    
    h, w, _ = frame.shape
    cat_h, cat_w = cat_resized.shape[:2]
    
    # å±…ä¸­ä½ç½®
    pos_x = (w - cat_w) // 2
    pos_y = (h - cat_h) // 2
    
    overlay_img(frame, cat_resized, pos_x, pos_y)
    
    if target_box is not None:
        x1, y1, x2, y2 = target_box
        cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
        # ç®­å¤´ä»å“ˆåŸºç±³ä¸­å¿ƒå‘å‡º
        start_pt = (pos_x + cat_w // 2, pos_y + cat_h // 2)
        cv2.arrowedLine(frame, start_pt, (cx, cy), (0, 255, 0), 3, tipLength=0.1)
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)


# ================= Modern GUI App =================

ctk.set_appearance_mode("Dark")
ctk.set_default_color_theme("blue")

class HajimiApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        
        # çª—å£è®¾ç½®
        self.title("Hajimi AI Assistant")
        self.geometry("1280x800")
        
        # å¸ƒå±€é…ç½®
        self.grid_columnconfigure(1, weight=1)
        self.grid_rowconfigure(0, weight=1)
        
        # --- å·¦ä¾§è¾¹æ  (æ—¥å¿—ä¸çŠ¶æ€) ---
        self.sidebar_frame = ctk.CTkFrame(self, width=250, corner_radius=0)
        self.sidebar_frame.grid(row=0, column=0, sticky="nsew")
        self.sidebar_frame.grid_rowconfigure(2, weight=1)
        
        self.logo_label = ctk.CTkLabel(self.sidebar_frame, text="Hajimi AI", font=ctk.CTkFont(size=24, weight="bold"))
        self.logo_label.grid(row=0, column=0, padx=20, pady=(20, 10))
        
        self.status_label = ctk.CTkLabel(self.sidebar_frame, text="çŠ¶æ€: åˆå§‹åŒ–ä¸­...", text_color="gray")
        self.status_label.grid(row=1, column=0, padx=20, pady=10)
        
        self.log_textbox = ctk.CTkTextbox(self.sidebar_frame, width=200)
        self.log_textbox.grid(row=2, column=0, padx=10, pady=10, sticky="nsew")

        # --- è®¾ç½®æŒ‰é’® ---
        self.settings_btn = ctk.CTkButton(self.sidebar_frame, text="âš™ï¸ è®¾ç½®æ¨¡å‹è·¯å¾„", 
                                          fg_color="transparent", border_width=1,
                                          command=self.open_settings)
        self.settings_btn.grid(row=3, column=0, padx=20, pady=10)
        
        # --- åº•éƒ¨ï¼šä½œè€…é“¾æ¥ ---
        self.link_label = ctk.CTkLabel(self.sidebar_frame, text="By Fz2hOpensource Team", 
                                       font=ctk.CTkFont(size=12, underline=True),
                                       text_color="lightblue", cursor="hand2")
        self.link_label.grid(row=4, column=0, pady=20)
        self.link_label.bind("<Button-1>", lambda e: webbrowser.open(USER_HOMEPAGE))
        
        # --- å³ä¾§ä¸»åŒºåŸŸ (è§†é¢‘æµ) ---
        self.video_frame = ctk.CTkFrame(self, corner_radius=0, fg_color="transparent")
        self.video_frame.grid(row=0, column=1, sticky="nsew")
        
        self.video_label = ctk.CTkLabel(self.video_frame, text="", corner_radius=10)
        self.video_label.pack(fill="both", expand=True, padx=20, pady=20)
        
        # --- åº•éƒ¨æŒ‡ä»¤æ˜¾ç¤º ---
        self.command_label = ctk.CTkLabel(self.video_frame, text="ç­‰å¾…è¯­éŸ³æŒ‡ä»¤...", 
                                          font=ctk.CTkFont(size=20),
                                          fg_color=("white", "gray20"), corner_radius=8)
        self.command_label.place(relx=0.5, rely=0.9, anchor="center")

        # --- å†…éƒ¨çŠ¶æ€ ---
        self.cap = None
        self.process = None
        self.msg_queue = None
        self.yolo_model = None
        self.known_vectors = {}
        self.last_voice_vector = None
        self.last_voice_text = ""
        self.cat_img = None
        
        # å»¶è¿Ÿåˆå§‹åŒ–ï¼Œç¡®ä¿ GUI å…ˆæ˜¾ç¤º
        self.after(100, self.start_system)

    def log(self, message):
        self.log_textbox.insert("end", message + "\n")
        self.log_textbox.see("end")

    def open_settings(self):
        """æ‰“å¼€è®¾ç½®çª—å£"""
        settings_window = ctk.CTkToplevel(self)
        settings_window.title("ç³»ç»Ÿè®¾ç½®")
        settings_window.geometry("600x400")
        settings_window.grab_set()  # æ¨¡æ€çª—å£

        # æ ‡é¢˜
        ctk.CTkLabel(settings_window, text="æ¨¡å‹è·¯å¾„è®¾ç½®", font=ctk.CTkFont(size=20, weight="bold")).pack(pady=20)

        # è¡¨å•å®¹å™¨
        form_frame = ctk.CTkFrame(settings_window)
        form_frame.pack(fill="both", expand=True, padx=20, pady=10)

        # 1. Vosk è·¯å¾„
        ctk.CTkLabel(form_frame, text="Vosk è¯­éŸ³æ¨¡å‹è·¯å¾„ (æ–‡ä»¶å¤¹):").grid(row=0, column=0, sticky="w", padx=10, pady=5)
        vosk_entry = ctk.CTkEntry(form_frame, width=300)
        vosk_entry.grid(row=1, column=0, padx=10, pady=5)
        vosk_entry.insert(0, VOSK_MODEL_PATH)
        
        def browse_vosk():
            path = filedialog.askdirectory(initialdir=BASE_DIR, title="é€‰æ‹© Vosk æ¨¡å‹æ–‡ä»¶å¤¹")
            if path:
                vosk_entry.delete(0, "end")
                vosk_entry.insert(0, path)
        
        ctk.CTkButton(form_frame, text="æµè§ˆ", width=60, command=browse_vosk).grid(row=1, column=1, padx=10)

        # 2. YOLO è·¯å¾„
        ctk.CTkLabel(form_frame, text="YOLO æ¨¡å‹è·¯å¾„ (.pt æ–‡ä»¶):").grid(row=2, column=0, sticky="w", padx=10, pady=(20, 5))
        yolo_entry = ctk.CTkEntry(form_frame, width=300)
        yolo_entry.grid(row=3, column=0, padx=10, pady=5)
        yolo_entry.insert(0, YOLO_MODEL_NAME)
        
        def browse_yolo():
            path = filedialog.askopenfilename(initialdir=BASE_DIR, title="é€‰æ‹© YOLO æ¨¡å‹æ–‡ä»¶", filetypes=[("YOLO Model", "*.pt")])
            if path:
                yolo_entry.delete(0, "end")
                yolo_entry.insert(0, path)
        
        ctk.CTkButton(form_frame, text="æµè§ˆ", width=60, command=browse_yolo).grid(row=3, column=1, padx=10)

        # ä¿å­˜æŒ‰é’®
        def save_and_close():
            new_config = {
                "vosk_path": vosk_entry.get(),
                "yolo_path": yolo_entry.get()
            }
            save_config(new_config)
            tk_msg = "é…ç½®å·²ä¿å­˜ï¼\nè¯·é‡å¯ç¨‹åºä»¥ç”Ÿæ•ˆã€‚"
            # ç®€å•çš„å¼¹çª—æç¤º (è¿™é‡Œç”¨ label æ¨¡æ‹Ÿï¼Œæˆ–è€… print)
            print(tk_msg)
            settings_window.destroy()
            self.log("é…ç½®å·²æ›´æ–°ï¼Œè¯·é‡å¯ç¨‹åºã€‚")

        ctk.CTkButton(settings_window, text="ä¿å­˜è®¾ç½®", command=save_and_close, fg_color="green").pack(pady=20)

    def start_system(self):
        self.log("æ­£åœ¨å¯åŠ¨ç³»ç»Ÿ...")
        ensure_cat_image()
        self.cat_img = cv2.imread("hajimi1.png", cv2.IMREAD_UNCHANGED)
        
        # 1. å¯åŠ¨å­è¿›ç¨‹
        self.msg_queue = mp.Queue()
        self.process = mp.Process(target=voice_process_run, 
                                  args=(self.msg_queue, EN_ZH_CACHE, VOSK_MODEL_PATH, EMBEDDING_MODEL_NAME))
        self.process.start()
        self.log("å­è¿›ç¨‹å·²å¯åŠ¨ï¼Œæ­£åœ¨åŠ è½½è¯­éŸ³æ¨¡å‹...")
        
        # 2. åŠ è½½ YOLO (è¿™å¯èƒ½ä¼šå¡é¡¿ä¸€ä¸‹ UIï¼Œå®é™…ç”Ÿäº§å¯ä»¥ç”¨çº¿ç¨‹åŠ è½½)
        self.log("æ­£åœ¨åŠ è½½ YOLO æ¨¡å‹...")
        # ä¸ºäº†ä¸å®Œå…¨å¡æ­» UIï¼Œä½¿ç”¨ after ç¨å¾®åˆ†æ­¥
        self.after(100, self.load_yolo)

    def load_yolo(self):
        try:
            self.yolo_model = YOLO(YOLO_MODEL_NAME)
            self.log("YOLO æ¨¡å‹åŠ è½½å®Œæˆ")
        except Exception as e:
            self.log(f"YOLO åŠ è½½å¤±è´¥: {e}")
            return
            
        # 3. æ‰“å¼€æ‘„åƒå¤´
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            self.log("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            return
            
        self.status_label.configure(text="çŠ¶æ€: è¿è¡Œä¸­", text_color="green")
        self.log("ç³»ç»Ÿå¯åŠ¨å®Œæˆï¼")
        
        # å¼€å§‹å¾ªç¯
        self.update_loop()

    def update_loop(self):
        if not self.cap or not self.cap.isOpened():
            return

        # 1. è¯»å–æ‘„åƒå¤´
        ret, frame = self.cap.read()
        if not ret:
            self.log("æ— æ³•è¯»å–è§†é¢‘å¸§")
            return
            
        frame = cv2.flip(frame, 1)

        # 2. å¤„ç†æ¶ˆæ¯é˜Ÿåˆ—
        while not self.msg_queue.empty():
            try:
                msg_type, data = self.msg_queue.get_nowait()
                if msg_type == "voice":
                    text, vec = data
                    self.log(f"æ”¶åˆ°æŒ‡ä»¤: {text}")
                    self.last_voice_text = text
                    self.last_voice_vector = vec
                    self.command_label.configure(text=f"æŒ‡ä»¤: {text}")
                elif msg_type == "init_vectors":
                    self.known_vectors = data
                    self.log(f"å·²æ¥æ”¶ {len(self.known_vectors)} ä¸ªç±»åˆ«çš„å‘é‡æ•°æ®")
                elif msg_type == "error":
                    self.log(f"[Error] {data}")
                elif msg_type == "log":
                    self.log(data)
            except:
                break

        # 3. YOLO æ£€æµ‹
        if self.yolo_model:
            results = self.yolo_model(frame, verbose=False)[0]
            scene_objects = []

            for box in results.boxes:
                cls_id = int(box.cls[0])
                en_name = self.yolo_model.names[cls_id]
                zh_name = EN_ZH_CACHE.get(en_name, en_name)
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                scene_objects.append({"zh": zh_name, "box": (x1, y1, x2, y2)})

            # 4. åŒ¹é…é€»è¾‘
            best_idx = -1
            best_score = 0.3 # é˜ˆå€¼
            
            if self.last_voice_vector is not None and self.known_vectors:
                for i, obj in enumerate(scene_objects):
                    if obj["zh"] in self.known_vectors:
                        obj_vec = self.known_vectors[obj["zh"]]
                        score = np.dot(obj_vec, self.last_voice_vector)
                        if score > best_score:
                            best_score = score
                            best_idx = i

            # 5. ç»˜åˆ¶
            for i, obj in enumerate(scene_objects):
                x1, y1, x2, y2 = obj["box"]
                color = (200, 200, 200)
                if i == best_idx: color = (0, 255, 0)
                
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                # ä½¿ç”¨ PIL ç»˜åˆ¶ä¸­æ–‡
                frame = draw_text_chinese(frame, obj["zh"], (x1, y1 - 30), color, 20)

            if best_idx != -1:
                draw_cat(frame, self.cat_img, scene_objects[best_idx]["box"])
            else:
                draw_cat(frame, self.cat_img)

        # 6. æ˜¾ç¤ºåˆ° Tkinter
        # OpenCV BGR -> RGB
        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img_pil = Image.fromarray(img_rgb)
        
        # è°ƒæ•´å¤§å°ä»¥é€‚åº”çª—å£ (å¯é€‰ï¼Œè¿™é‡Œç®€å•ç¼©æ”¾)
        # è·å– label çš„å½“å‰å¤§å°
        # w = self.video_label.winfo_width()
        # h = self.video_label.winfo_height()
        # if w > 10 and h > 10:
        #    img_pil = img_pil.resize((w, h), Image.Resampling.LANCZOS)
        
        # è½¬æ¢ä¸º CTkImage
        ctk_img = ctk.CTkImage(light_image=img_pil, dark_image=img_pil, size=img_pil.size)
        self.video_label.configure(image=ctk_img)
        self.video_label.image = ctk_img # é˜²æ­¢åƒåœ¾å›æ”¶

        # å¾ªç¯
        self.after(10, self.update_loop)

    def on_closing(self):
        if self.cap:
            self.cap.release()
        if self.process:
            self.process.terminate()
        self.destroy()

if __name__ == "__main__":
    # å¿…é¡»è°ƒç”¨ï¼Œé˜²æ­¢ Windows ä¸‹å¤šè¿›ç¨‹å‡ºé”™
    mp.freeze_support()
    
    app = HajimiApp()
    app.protocol("WM_DELETE_WINDOW", app.on_closing)
    app.mainloop()
    

    def on_closing(self):
        if self.cap:
            self.cap.release()
        if self.process:
            self.process.terminate()
        self.destroy()